{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ReZNet: (Up to 6x) faster ResNet training with ReZero\n",
    "\n",
    "In this notebook we will examine how the [ReZero](https://arxiv.org/abs/2003.04887) architecture addition enables or accelerates training in deep [ResNet](https://arxiv.org/pdf/1512.03385.pdf) networks. We will find for example that for a ResNet110 the number of epochs to reach 50% accuracy decreases by a factor of 7 upon implementing ReZero. In this particular example the accuracy after convergence also improves with ReZero. The architecture here differs importantly from [Fixup](https://arxiv.org/pdf/1901.09321.pdf) and [SkipInit](https://arxiv.org/pdf/2002.10444.pdf) in that the skip connection is implemented **after** the nonlinearity to preserve signal propagation.\n",
    "\n",
    "The official ReZero repo is [here](https://github.com/majumderb/rezero).\n",
    "\n",
    "This notebook is heavily inspired by [Yerlan Idelbayev's beautiful ResNet implementation](https://github.com/akamaster/pytorch_resnet_cifar10).\n",
    "\n",
    "Running time of the notebook: 15 minutes on laptop with single RTX 2060 GPU.\n",
    "\n",
    "Note: This notebook as evaluated with PyTorch 1.4, the test accuracies may differ slightly for other versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Import and set manual seed\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "######################################################################\n",
    "# Define ResNet model as in \n",
    "# https://github.com/akamaster/pytorch_resnet_cifar10\n",
    "\n",
    "def _weights_init(m):\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, option='A', rezero = True):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.rezero = rezero\n",
    "        if self.rezero:\n",
    "            self.resweight = self.resweight = nn.Parameter(torch.Tensor([0]), requires_grad=True)\n",
    "            \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = LambdaLayer(lambda x:\n",
    "                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        \n",
    "        if self.rezero == True:\n",
    "            # In a ReZero ResNet the skip connection is after the nonlinearity\n",
    "            out = self.resweight * F.relu(out) + self.shortcut(x)\n",
    "        elif self.rezero == False:\n",
    "            # In a vanilla ResNet the skip connection is before the nonlinearity\n",
    "            out = F.relu(out + self.shortcut(x))\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10, rezero = False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1, rezero = rezero)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2, rezero = rezero)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2, rezero = rezero)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride, rezero = False):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride, rezero = rezero))\n",
    "            self.in_planes = planes * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "######################################################################\n",
    "# Define various variants\n",
    "\n",
    "def resnet20(rezero = False):\n",
    "    return ResNet(BasicBlock, [3, 3, 3], rezero = rezero)\n",
    "\n",
    "\n",
    "def resnet56(rezero = False):\n",
    "    return ResNet(BasicBlock, [9, 9, 9], rezero = rezero)\n",
    "\n",
    "\n",
    "def resnet110(rezero = False):\n",
    "    return ResNet(BasicBlock, [18, 18, 18], rezero = rezero)\n",
    "\n",
    "\n",
    "def test(net):\n",
    "    import numpy as np\n",
    "    total_params = 0\n",
    "\n",
    "    for x in filter(lambda p: p.requires_grad, net.parameters()):\n",
    "        total_params += np.prod(x.data.numpy().shape)\n",
    "    print(\"Total number of params {:2.3f}M\".format(total_params/1e6))\n",
    "    print(\"Total layers\", len(list(filter(lambda p: p.requires_grad and len(p.data.size())>1, net.parameters()))))\n",
    "\n",
    "######################################################################\n",
    "# Define function to train\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch,print_freq,lr_scheduler):\n",
    "    \"\"\"\n",
    "        Run one train epoch\n",
    "    \"\"\"\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        target = target.cuda()\n",
    "        input_var = input.cuda()\n",
    "        target_var = target\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        output = output.float()\n",
    "        loss = loss.float()\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(output.data, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec1.item(), input.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "            \n",
    "        if i % print_freq == 0:   \n",
    "            print('| epoch {:3d} | {:4d}/{:4d} batches | '\n",
    "          'lr {:02.2f} | ms/batch {:4.0f} | '\n",
    "          'loss {loss.avg:1.3f} | Top 1 accuracy {top1.avg:2.2f} %'.format(\n",
    "            epoch+1, i, len(train_loader), lr_scheduler.get_lr()[0],\n",
    "            1000*batch_time.avg,loss=losses,top1=top1))\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    \"\"\"\n",
    "    Run evaluation\n",
    "    \"\"\"\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            target = target.cuda()\n",
    "            input_var = input.cuda()\n",
    "            target_var = target.cuda()\n",
    "\n",
    "\n",
    "            # compute output\n",
    "            output = model(input_var)\n",
    "            loss = criterion(output, target_var)\n",
    "\n",
    "            output = output.float()\n",
    "            loss = loss.float()\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1 = accuracy(output.data, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec1.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            \n",
    "\n",
    "    return losses.avg, top1.avg\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "######################################################################\n",
    "# Package model setup and training into one simple function\n",
    "\n",
    "def setup_and_train(model,batch_size = 128, lr = 0.1,momentum = 0.9,\n",
    "                    weight_decay = 1e-4,epochs = 200,print_freq = 50):\n",
    "    model = model.to(device)\n",
    "    start_epoch = 0\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10(root='./data', train=True, transform=transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(32, 4),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]), download=True),\n",
    "        batch_size=batch_size, shuffle=True,\n",
    "        num_workers=1, pin_memory=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10(root='./data', train=False, transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                        normalize,\n",
    "                ])),\n",
    "        batch_size=128, shuffle=False,\n",
    "        num_workers=1, pin_memory=True)\n",
    "\n",
    "    # define loss function (criterion) and pptimizer\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr,\n",
    "                            momentum=momentum,\n",
    "                            weight_decay=weight_decay)\n",
    "\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                                    milestones=[100, 150], last_epoch=start_epoch - 1)\n",
    "    best_prec1 = 0\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        print('-'*95)\n",
    "        train(train_loader, model, criterion, optimizer, epoch,print_freq,lr_scheduler)\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        # evaluate on validation set\n",
    "        loss, prec1 = validate(val_loader, model, criterion)\n",
    "\n",
    "        # remember best prec@1 \n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "\n",
    "        print('-'*95)\n",
    "        print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:1.3f} | '\n",
    "              'valid precision {:3.2f}% (best: {:3.2f}%) '.format(epoch+1, (time.time() - epoch_start_time),\n",
    "                                         loss, prec1,best_prec1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet20\n",
    "\n",
    "First, we train a ResNet20 for with ReZero for one epoch, and then train a ResNet20 without Rezero until it achieves the same accuracy.\n",
    "\n",
    "* In this example ReZero accelerates initial training by a factor of about 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of params 0.270M\n",
      "Total layers 20\n",
      "Files already downloaded and verified\n",
      "-----------------------------------------------------------------------------------------------\n",
      "| epoch   1 |    0/ 391 batches | lr 0.20 | ms/batch  322 | loss 2.382 | Top 1 accuracy 5.47 %\n",
      "| epoch   1 |  130/ 391 batches | lr 0.20 | ms/batch   35 | loss 1.826 | Top 1 accuracy 31.22 %\n",
      "| epoch   1 |  260/ 391 batches | lr 0.20 | ms/batch   33 | loss 1.665 | Top 1 accuracy 38.30 %\n",
      "| epoch   1 |  390/ 391 batches | lr 0.20 | ms/batch   33 | loss 1.557 | Top 1 accuracy 42.68 %\n",
      "-----------------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 14.14s | valid loss 1.507 | valid precision 49.52% (best: 49.52%) \n"
     ]
    }
   ],
   "source": [
    "model = resnet20(rezero=True)\n",
    "test(model)\n",
    "setup_and_train(model, batch_size = 128, lr = 0.2, epochs = 1, print_freq = 130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of params 0.270M\n",
      "Total layers 20\n",
      "Files already downloaded and verified\n",
      "-----------------------------------------------------------------------------------------------\n",
      "| epoch   1 |    0/ 391 batches | lr 0.20 | ms/batch   71 | loss 3.223 | Top 1 accuracy 9.38 %\n",
      "| epoch   1 |  130/ 391 batches | lr 0.20 | ms/batch   31 | loss 2.108 | Top 1 accuracy 23.83 %\n",
      "| epoch   1 |  260/ 391 batches | lr 0.20 | ms/batch   31 | loss 1.895 | Top 1 accuracy 29.94 %\n",
      "| epoch   1 |  390/ 391 batches | lr 0.20 | ms/batch   31 | loss 1.780 | Top 1 accuracy 34.10 %\n",
      "-----------------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 13.35s | valid loss 1.556 | valid precision 43.43% (best: 43.43%) \n",
      "-----------------------------------------------------------------------------------------------\n",
      "| epoch   2 |    0/ 391 batches | lr 0.20 | ms/batch   79 | loss 1.460 | Top 1 accuracy 46.09 %\n",
      "| epoch   2 |  130/ 391 batches | lr 0.20 | ms/batch   31 | loss 1.441 | Top 1 accuracy 46.95 %\n",
      "| epoch   2 |  260/ 391 batches | lr 0.20 | ms/batch   31 | loss 1.374 | Top 1 accuracy 49.59 %\n",
      "| epoch   2 |  390/ 391 batches | lr 0.20 | ms/batch   31 | loss 1.327 | Top 1 accuracy 51.55 %\n",
      "-----------------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 13.39s | valid loss 1.260 | valid precision 55.54% (best: 55.54%) \n"
     ]
    }
   ],
   "source": [
    "model = resnet20(rezero=False)\n",
    "test(model)\n",
    "setup_and_train(model, batch_size = 128, lr = 0.2, epochs = 2, print_freq = 130)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet56\n",
    "\n",
    "Next, we train a ResNet56 for one epoch, and then train a ResNet56 without Rezero until it achieves the same accuracy.\n",
    "\n",
    "* In this example ReZero accelerates initial training by a factor of about 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of params 0.853M\n",
      "Total layers 56\n",
      "Files already downloaded and verified\n",
      "-----------------------------------------------------------------------------------------------\n",
      "| epoch   1 |    0/ 391 batches | lr 0.10 | ms/batch  133 | loss 2.377 | Top 1 accuracy 3.12 %\n",
      "| epoch   1 |  130/ 391 batches | lr 0.10 | ms/batch   94 | loss 1.800 | Top 1 accuracy 31.95 %\n",
      "| epoch   1 |  260/ 391 batches | lr 0.10 | ms/batch   94 | loss 1.631 | Top 1 accuracy 39.12 %\n",
      "| epoch   1 |  390/ 391 batches | lr 0.10 | ms/batch   94 | loss 1.494 | Top 1 accuracy 44.63 %\n",
      "-----------------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 39.11s | valid loss 1.339 | valid precision 53.50% (best: 53.50%) \n"
     ]
    }
   ],
   "source": [
    "model = resnet56(rezero=True)\n",
    "test(model)\n",
    "setup_and_train(model, batch_size = 128, lr = 0.1, epochs = 1, print_freq = 130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of params 0.853M\n",
      "Total layers 56\n",
      "Files already downloaded and verified\n",
      "-----------------------------------------------------------------------------------------------\n",
      "| epoch   1 |    0/ 391 batches | lr 0.10 | ms/batch  130 | loss 11.472 | Top 1 accuracy 8.59 %\n",
      "| epoch   1 |  130/ 391 batches | lr 0.10 | ms/batch   89 | loss 2.912 | Top 1 accuracy 10.69 %\n",
      "| epoch   1 |  260/ 391 batches | lr 0.10 | ms/batch   89 | loss 2.573 | Top 1 accuracy 12.43 %\n",
      "| epoch   1 |  390/ 391 batches | lr 0.10 | ms/batch   89 | loss 2.388 | Top 1 accuracy 16.01 %\n",
      "-----------------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 37.08s | valid loss 1.904 | valid precision 26.63% (best: 26.63%) \n",
      "-----------------------------------------------------------------------------------------------\n",
      "| epoch   2 |    0/ 391 batches | lr 0.10 | ms/batch  134 | loss 1.885 | Top 1 accuracy 27.34 %\n",
      "| epoch   2 |  130/ 391 batches | lr 0.10 | ms/batch   90 | loss 1.875 | Top 1 accuracy 29.13 %\n",
      "| epoch   2 |  260/ 391 batches | lr 0.10 | ms/batch   90 | loss 1.805 | Top 1 accuracy 31.76 %\n",
      "| epoch   2 |  390/ 391 batches | lr 0.10 | ms/batch   90 | loss 1.749 | Top 1 accuracy 34.07 %\n",
      "-----------------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 37.38s | valid loss 1.682 | valid precision 38.90% (best: 38.90%) \n",
      "-----------------------------------------------------------------------------------------------\n",
      "| epoch   3 |    0/ 391 batches | lr 0.10 | ms/batch  138 | loss 1.634 | Top 1 accuracy 36.72 %\n",
      "| epoch   3 |  130/ 391 batches | lr 0.10 | ms/batch   90 | loss 1.537 | Top 1 accuracy 42.96 %\n",
      "| epoch   3 |  260/ 391 batches | lr 0.10 | ms/batch   90 | loss 1.462 | Top 1 accuracy 46.00 %\n",
      "| epoch   3 |  390/ 391 batches | lr 0.10 | ms/batch   90 | loss 1.400 | Top 1 accuracy 48.51 %\n",
      "-----------------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 37.47s | valid loss 1.262 | valid precision 54.77% (best: 54.77%) \n",
      "-----------------------------------------------------------------------------------------------\n",
      "| epoch   4 |    0/ 391 batches | lr 0.10 | ms/batch  135 | loss 1.263 | Top 1 accuracy 55.47 %\n",
      "| epoch   4 |  130/ 391 batches | lr 0.10 | ms/batch   91 | loss 1.183 | Top 1 accuracy 57.22 %\n",
      "| epoch   4 |  260/ 391 batches | lr 0.10 | ms/batch   90 | loss 1.147 | Top 1 accuracy 58.76 %\n",
      "| epoch   4 |  390/ 391 batches | lr 0.10 | ms/batch   90 | loss 1.102 | Top 1 accuracy 60.59 %\n",
      "-----------------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 37.46s | valid loss 0.997 | valid precision 64.64% (best: 64.64%) \n"
     ]
    }
   ],
   "source": [
    "model = resnet56(rezero=False)\n",
    "test(model)\n",
    "setup_and_train(model, batch_size = 128, lr = 0.1, epochs = 4, print_freq = 130)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet110\n",
    "\n",
    "Next, we train a ResNet110 for one epoch, and then train a ResNet110 without Rezero until it achieves the same accuracy.\n",
    "\n",
    "* In this example ReZero accelerates initial training by a factor of about 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of params 1.728M\n",
      "Total layers 110\n",
      "Files already downloaded and verified\n",
      "-----------------------------------------------------------------------------------------------\n",
      "| epoch   1 |    0/ 391 batches | lr 0.10 | ms/batch  223 | loss 2.402 | Top 1 accuracy 9.38 %\n",
      "| epoch   1 |  130/ 391 batches | lr 0.10 | ms/batch  189 | loss 1.793 | Top 1 accuracy 32.82 %\n",
      "| epoch   1 |  260/ 391 batches | lr 0.10 | ms/batch  189 | loss 1.589 | Top 1 accuracy 41.12 %\n",
      "| epoch   1 |  390/ 391 batches | lr 0.10 | ms/batch  189 | loss 1.440 | Top 1 accuracy 47.20 %\n",
      "-----------------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 78.27s | valid loss 1.641 | valid precision 50.65% (best: 50.65%) \n"
     ]
    }
   ],
   "source": [
    "model = resnet110(rezero=True)\n",
    "test(model)\n",
    "setup_and_train(model, batch_size = 128, lr = 0.1, epochs = 1, print_freq = 130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of params 1.728M\n",
      "Total layers 110\n",
      "Files already downloaded and verified\n",
      "-----------------------------------------------------------------------------------------------\n",
      "| epoch   1 |    0/ 391 batches | lr 0.10 | ms/batch  222 | loss 12.921 | Top 1 accuracy 10.16 %\n",
      "| epoch   1 |  130/ 391 batches | lr 0.10 | ms/batch  178 | loss 3.905 | Top 1 accuracy 11.36 %\n",
      "| epoch   1 |  260/ 391 batches | lr 0.10 | ms/batch  177 | loss 3.072 | Top 1 accuracy 13.86 %\n",
      "| epoch   1 |  390/ 391 batches | lr 0.10 | ms/batch  177 | loss 2.731 | Top 1 accuracy 17.16 %\n",
      "-----------------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 73.58s | valid loss 1.948 | valid precision 27.01% (best: 27.01%) \n",
      "-----------------------------------------------------------------------------------------------\n",
      "| epoch   2 |    0/ 391 batches | lr 0.10 | ms/batch  223 | loss 2.013 | Top 1 accuracy 25.00 %\n",
      "| epoch   2 |  130/ 391 batches | lr 0.10 | ms/batch  178 | loss 1.936 | Top 1 accuracy 27.21 %\n",
      "| epoch   2 |  260/ 391 batches | lr 0.10 | ms/batch  178 | loss 1.892 | Top 1 accuracy 29.00 %\n",
      "| epoch   2 |  390/ 391 batches | lr 0.10 | ms/batch  178 | loss 1.854 | Top 1 accuracy 30.55 %\n",
      "-----------------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 73.73s | valid loss 2.182 | valid precision 36.19% (best: 36.19%) \n",
      "-----------------------------------------------------------------------------------------------\n",
      "| epoch   3 |    0/ 391 batches | lr 0.10 | ms/batch  223 | loss 1.756 | Top 1 accuracy 35.16 %\n",
      "| epoch   3 |  130/ 391 batches | lr 0.10 | ms/batch  178 | loss 1.721 | Top 1 accuracy 35.91 %\n",
      "| epoch   3 |  260/ 391 batches | lr 0.10 | ms/batch  178 | loss 1.694 | Top 1 accuracy 37.33 %\n",
      "| epoch   3 |  390/ 391 batches | lr 0.10 | ms/batch  178 | loss 1.668 | Top 1 accuracy 38.35 %\n",
      "-----------------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 73.83s | valid loss 1.855 | valid precision 41.56% (best: 41.56%) \n",
      "-----------------------------------------------------------------------------------------------\n",
      "| epoch   4 |    0/ 391 batches | lr 0.10 | ms/batch  223 | loss 1.597 | Top 1 accuracy 47.66 %\n",
      "| epoch   4 |  130/ 391 batches | lr 0.10 | ms/batch  178 | loss 1.550 | Top 1 accuracy 43.44 %\n",
      "| epoch   4 |  260/ 391 batches | lr 0.10 | ms/batch  178 | loss 1.534 | Top 1 accuracy 43.91 %\n",
      "| epoch   4 |  390/ 391 batches | lr 0.10 | ms/batch  178 | loss 1.517 | Top 1 accuracy 44.51 %\n",
      "-----------------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 73.94s | valid loss 1.819 | valid precision 39.79% (best: 41.56%) \n",
      "-----------------------------------------------------------------------------------------------\n",
      "| epoch   5 |    0/ 391 batches | lr 0.10 | ms/batch  223 | loss 1.387 | Top 1 accuracy 50.78 %\n",
      "| epoch   5 |  130/ 391 batches | lr 0.10 | ms/batch  178 | loss 1.438 | Top 1 accuracy 47.84 %\n",
      "| epoch   5 |  260/ 391 batches | lr 0.10 | ms/batch  178 | loss 1.419 | Top 1 accuracy 48.65 %\n",
      "| epoch   5 |  390/ 391 batches | lr 0.10 | ms/batch  178 | loss 1.405 | Top 1 accuracy 49.18 %\n",
      "-----------------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 73.97s | valid loss 1.450 | valid precision 50.40% (best: 50.40%) \n",
      "-----------------------------------------------------------------------------------------------\n",
      "| epoch   6 |    0/ 391 batches | lr 0.10 | ms/batch  224 | loss 1.421 | Top 1 accuracy 46.88 %\n",
      "| epoch   6 |  130/ 391 batches | lr 0.10 | ms/batch  179 | loss 1.353 | Top 1 accuracy 51.16 %\n",
      "| epoch   6 |  260/ 391 batches | lr 0.10 | ms/batch  179 | loss 1.330 | Top 1 accuracy 51.77 %\n",
      "| epoch   6 |  390/ 391 batches | lr 0.10 | ms/batch  178 | loss 1.316 | Top 1 accuracy 52.22 %\n",
      "-----------------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 74.00s | valid loss 1.273 | valid precision 55.72% (best: 55.72%) \n",
      "-----------------------------------------------------------------------------------------------\n",
      "| epoch   7 |    0/ 391 batches | lr 0.10 | ms/batch  225 | loss 1.224 | Top 1 accuracy 50.78 %\n",
      "| epoch   7 |  130/ 391 batches | lr 0.10 | ms/batch  179 | loss 1.245 | Top 1 accuracy 55.36 %\n",
      "| epoch   7 |  260/ 391 batches | lr 0.10 | ms/batch  178 | loss 1.241 | Top 1 accuracy 55.46 %\n",
      "| epoch   7 |  390/ 391 batches | lr 0.10 | ms/batch  178 | loss 1.226 | Top 1 accuracy 56.03 %\n",
      "-----------------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 73.95s | valid loss 1.222 | valid precision 58.21% (best: 58.21%) \n",
      "-----------------------------------------------------------------------------------------------\n",
      "| epoch   8 |    0/ 391 batches | lr 0.10 | ms/batch  222 | loss 1.029 | Top 1 accuracy 64.84 %\n",
      "| epoch   8 |  130/ 391 batches | lr 0.10 | ms/batch  179 | loss 1.161 | Top 1 accuracy 58.47 %\n",
      "| epoch   8 |  260/ 391 batches | lr 0.10 | ms/batch  178 | loss 1.155 | Top 1 accuracy 58.92 %\n",
      "| epoch   8 |  390/ 391 batches | lr 0.10 | ms/batch  178 | loss 1.143 | Top 1 accuracy 59.37 %\n",
      "-----------------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 73.99s | valid loss 1.488 | valid precision 54.72% (best: 58.21%) \n"
     ]
    }
   ],
   "source": [
    "model = resnet110(rezero=False)\n",
    "test(model)\n",
    "setup_and_train(model, batch_size = 128, lr = 0.1, epochs = 8, print_freq = 130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
